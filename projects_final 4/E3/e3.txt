A1) We can see the malloc call to allocate space in the put function. When we are using pthread, malloc call becomes thread safe as the heap is shared space across the process. Therefore to make sure same space is not allocated to multiple threads malloc runs by keeping a lock on its own which is the feature of the operating system. Hence because of malloc, put doesn't speed up even though parallel programming is enabled.	

A2) If there is only one thread, all the put functions and the respective insert functions happen one after another causing no problem at all. If there are 2 or more threads then the problem arises due to the insert function. Let us say a thread called the insert function and is trying to update the ith table with key1 and value1. It will be something as follows.

	insert(key1, value1, &table[i], table[i]);

	After thread1 enters the insert function, let us say parallelly another thread starts to do the put operations. If this second thread also, is trying to update the same ith table, then it is a problem, cause it is shared table. Lets say thread1 completes the insert first and updates the base address of the ith table and assumes everything is fine. But the second thread which has already started, doesn't know about this update which the thread1 did, and so it updates the base address with its entry value there by overwriting the update which was done by thread1. Hence a key will be missed from the hash table.

	Hence, 2 or more threads have this overwrite problem as the hashtable is a shared resource. This leads to missing of the keys.

A3) Yes the two threaded version is faster than the single threaded version. It is correct after we implement lock in the put function.

A4) Since the get operations are not changing the table entries, no locks are needed here. Locks are needed only for the put operations as the buckets are being overwritten. Also, initially I have put a lock for the whole insert function leading to less optimized code. The problem is only if multiple threads update the same bucket, not if each one is updating a different one. Hence putting a lock per bucket optimizes the code. Now the put operations run much faster.

A5) I tested the code with thread values 1,2,4,8,16,32 and 80. At the time I was running cs2 machine had 15 processes each with 8 cores. The improvement in performance by increasing the threads from 1 to 2 and 2 to 4 was high. But threads 4 to 8 and 8 to 16 didn't improve the performance that much when compared to 2 to 4 threads improvement. Increasing threads from 16 to 32 decreased the performance. 80 threads showed even poor performance. Hence due to the overhead of parallel programming, for every code there will be the optimum number of threads for which the performance will the best. Beyond that point performance drops.


