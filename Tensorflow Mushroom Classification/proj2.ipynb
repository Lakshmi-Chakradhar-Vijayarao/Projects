{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5375 images belonging to 9 classes.\n",
      "Found 1339 images belonging to 9 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting initial training...\n",
      "Epoch 1/20\n",
      "168/168 [==============================] - 56s 328ms/step - loss: 1.2475 - accuracy: 0.5736 - val_loss: 1.1191 - val_accuracy: 0.6094\n",
      "Epoch 2/20\n",
      "168/168 [==============================] - 58s 342ms/step - loss: 0.8798 - accuracy: 0.6945 - val_loss: 1.0252 - val_accuracy: 0.6453\n",
      "Epoch 3/20\n",
      "168/168 [==============================] - 69s 412ms/step - loss: 0.7652 - accuracy: 0.7336 - val_loss: 1.0360 - val_accuracy: 0.6400\n",
      "Epoch 4/20\n",
      "168/168 [==============================] - 81s 480ms/step - loss: 0.7042 - accuracy: 0.7498 - val_loss: 1.1035 - val_accuracy: 0.6206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy before fine-tuning: 0.6206\n",
      "\n",
      "Unfreezing and starting fine-tuning...\n",
      "Epoch 1/10\n",
      "168/168 [==============================] - 280s 2s/step - loss: 1.1094 - accuracy: 0.6128 - val_loss: 1.0086 - val_accuracy: 0.6460\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 278s 2s/step - loss: 0.8787 - accuracy: 0.7021 - val_loss: 1.0042 - val_accuracy: 0.6580\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 277s 2s/step - loss: 0.7910 - accuracy: 0.7233 - val_loss: 1.0168 - val_accuracy: 0.6490\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 281s 2s/step - loss: 0.7110 - accuracy: 0.7596 - val_loss: 0.9971 - val_accuracy: 0.6624\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 321s 2s/step - loss: 0.6596 - accuracy: 0.7682 - val_loss: 0.9814 - val_accuracy: 0.6535\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 359s 2s/step - loss: 0.6010 - accuracy: 0.7927 - val_loss: 0.9874 - val_accuracy: 0.6692\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 322s 2s/step - loss: 0.5575 - accuracy: 0.8119 - val_loss: 0.9197 - val_accuracy: 0.6826\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 315s 2s/step - loss: 0.5066 - accuracy: 0.8296 - val_loss: 0.8836 - val_accuracy: 0.6923\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 320s 2s/step - loss: 0.4732 - accuracy: 0.8396 - val_loss: 0.9003 - val_accuracy: 0.6931\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 316s 2s/step - loss: 0.4442 - accuracy: 0.8530 - val_loss: 0.8918 - val_accuracy: 0.6908\n",
      "\n",
      "Final Validation Accuracy: 69.08%\n",
      "Final Training Accuracy: 85.30%\n",
      " Final Model Saved as 'mushroom_model.h5'\n",
      " Final Weights Saved as 'mushroom_model_weights.h5'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import ImageFile\n",
    "\n",
    "# Allow loading truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Constants\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_INITIAL = 20\n",
    "EPOCHS_FINE_TUNE = 10\n",
    "DATA_DIR = \"Mushrooms\"  # Training and validation dataset directory\n",
    "\n",
    "# Step 1: Data generators with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Train & Validation Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "# Step 2: Load MobileNetV2 base\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  # Freeze base initially\n",
    "\n",
    "# Step 3: Add custom classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Step 4: Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Step 5: Initial training\n",
    "print(\"Starting initial training...\")\n",
    "history_initial = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS_INITIAL,\n",
    "    callbacks=[EarlyStopping(patience=2, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# Step 6: Accuracy after initial training\n",
    "initial_val_acc = history_initial.history['val_accuracy'][-1]\n",
    "print(f\"\\nModel Accuracy before fine-tuning: {initial_val_acc:.4f}\")\n",
    "\n",
    "# Step 7: Fine-tuning\n",
    "print(\"\\nUnfreezing and starting fine-tuning...\")\n",
    "base_model.trainable = True\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS_FINE_TUNE,\n",
    "    callbacks=[EarlyStopping(patience=3, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# Step 8: Final evaluation on validation\n",
    "final_val_acc = history_fine.history['val_accuracy'][-1]\n",
    "final_train_acc = history_fine.history['accuracy'][-1]\n",
    "print(f\"\\nFinal Validation Accuracy: {final_val_acc * 100:.2f}%\")\n",
    "print(f\"Final Training Accuracy: {final_train_acc * 100:.2f}%\")\n",
    "\n",
    "# Step 9: Save model and weights\n",
    "model.save(\"mushroom_model.h5\")\n",
    "model.save_weights(\"mushroom_model_weights.h5\")\n",
    "print(\" Final Model Saved as 'mushroom_model.h5'\")\n",
    "print(\" Final Weights Saved as 'mushroom_model_weights.h5'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
